{
    "vocab_size":1,
    "hidden_size": 8,
    "num_hidden_layers": 6,
    "num_attention_heads":4,
    "intermediate_size": 32,
    "act_fn":"tanh",
    "initializer_range": 0.05,
    "dropout": 0.1,
    "hidden_dropout_prob": 0.1,
    "attn_dropout": 0.1,
    "seq_len": 1000
  }